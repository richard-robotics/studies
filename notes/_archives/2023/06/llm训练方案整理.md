LLM 训练方案整理
===
<!--START_SECTION:badge-->

![last modify](https://img.shields.io/static/v1?label=last%20modify&message=2023-06-25%2020%3A27%3A08&color=yellowgreen&style=flat-square)

<!--END_SECTION:badge-->
<!--info
top: false
hidden: false
-->

> ***Keywords**: LLM*

<!--START_SECTION:toc-->
- [方案整理](#方案整理)
    - [ColossalAI](#colossalai)
    - [Alpaca](#alpaca)
<!--END_SECTION:toc-->


## 方案整理

### ColossalAI
- 代码: [ColossalAI/applications/Chat · GitHub](https://github.com/hpcaitech/ColossalAI/tree/main/applications/Chat)
- 博客: [ColossalChat: An Open-Source Solution for Cloning ChatGPT With a Complete RLHF Pipeline | by Yang You | PyTorch | Medium](https://medium.com/pytorch/colossalchat-an-open-source-solution-for-cloning-chatgpt-with-a-complete-rlhf-pipeline-5edf08fb538b)

### Alpaca
- [stanford_alpaca: Code and documentation to train Stanford's Alpaca models, and generate the data.](https://github.com/tatsu-lab/stanford_alpaca)
- [alpaca-lora: Instruct-tune LLaMA on consumer hardware · GitHub](https://github.com/tloen/alpaca-lora#training-finetunepy)

